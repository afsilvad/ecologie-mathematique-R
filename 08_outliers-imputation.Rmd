---
title: "Détection de valeurs aberrantes et imputation de données manquantes"
author: "Serge-Étienne Parent"
date: "`r format(Sys.Date())`"
output: github_document
---

# Détection de valeurs aberrantes et imputation de données manquantes {#chapitre-outliers}


 ***
️\ **Objectifs spécifiques**:

À la fin de ce chapitre, vous

- saurez comment détecter des valeurs aberrantes en mode univarié et multivarié
- saurez comment procéder à l'imputation de valeurs manquantes en mode univarié et multivarié

 ***


Les données environnementales sont généralement recueillies à différentes échelles et concernent plusieurs sites, plusieurs variables (corrélées ou non), impliquent différents individus de différentes agences et peuvent s'étendre sur plusieurs années (Alameddine et al., 2010; Lokupitiya et al., 2006). De ce fait, la plupart de ces bases de données contiennent des valeurs manquantes et/ou aberrantes liées à différentes sources d’erreurs, pouvant parfois limiter l'utilité des inférences statistiques (Collins et al., 2001; Glasson-Cicognani et Berchtold, 2010). Il convient alors de les traiter correctement avant d’effectuer les analyses statistiques car les ignorer peut entraîner, outre une perte de précision, de forts biais dans les modèles d’analyse (Alameddine et al., 2010; Filzmoser et al., 2008; Glasson-Cicognani et Berchtold, 2010). 

## Données manquantes, définition, origine, typologie et traitement

### Définition

Les tableaux de données sont organisés en lignes et colonnes. Les lignes représentent les observations, les unités, les sujets ou les cas étudiés selon le contexte, et les colonnes représentent les variables mesurées pour chaque observation. Les entrées qui sont les valeurs (ou contenus) des cellules ou encore les valeurs observées, peuvent être des valeurs continues, ou des valeurs catégoriales (Little et Rubin, 2002). Considérant une variable aléatoire $X$ quelconque, une donnée manquante $x_m$, est une donnée pour laquelle la valeur  de la variable $X$ est inconnue (ou absente). En d’autres termes, on ne dispose pas de la valeur de X pour le sujet i donné. C’est une donnée non disponible qui serait utile pour l’analyse si elle était observée (Ware  et al., 2012).

La littérature sur les données manquantes est plus abondante dans les domaines des sciences sociales sur les données d’enquêtes, et des sciences médicales (Davey et al., 2001; Graham, 2012). Pour représenter leur répartition dans la table de données, une matrice indicatrice des valeurs manquantes $M = (m_{ij})$ est généralement utilisée où $m_{ij}$ est une variable binaire qui prend la valeur 1 si la valeur de la variable (X) est observée et 0 si  est absent (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002).

### Origines des données manquantes

Les données manquantes ont des origines matérielles diverses. Des valeurs peuvent être absentes soit parce qu’elles n’ont pas été observées, ou qu’elles ont été perdues ou étaient incohérentes (Glasson-Cicognani et Berchtold, 2010). La donnée peut avoir été simplement perdue lors de la collecte ou du processus d’enregistrement des données, ou en raison du dysfonctionnement d’un équipement, en raison d'une contamination, ou que la personne responsable de la collecte de données ait simplement oublié d'obtenir cette mesure particulière (Graham, 2012). Pour une base colligeant des résultats de plusieurs études, certaines variables peuvent ne pas avoir été étudiées pour un essai donné selon les objectifs de l’étude.

### Profils des données manquantes

Les auteurs traitant des données manquantes distinguent des formes de répartition des données manquantes et des mécanismes conduisant à ces dernières. La répartition des données manquantes décrit les dispositions des valeurs présentes et celles qui sont manquantes dans la matrice indicatrice. Les mécanismes à l’origine des données manquantes décrivent la relation probabiliste entre les valeurs observées et les valeurs manquantes de la table de données.

#### Répartition des données manquantes

Les données manquantes se répartissent selon différents cas de figures (Graham, 2012; Little et Rubin, 2002) dont les trois principaux sont les valeurs manquantes univariées, les valeurs manquantes monotones et celles non monotones ou arbitraires. Cette distinction est fonction de la matrice indicatrice des valeurs manquantes. Cette matrice est dite à valeurs manquantes univariées ou de non-réponse univariée, lorsque pour une variable donnée, si une observation est absente, alors toutes les observations suivantes pour cette variable sont absentes (figure 1.a). En expérimentation agricole, ce cas de figure est qualifié de problème de la parcelle manquante où, pour une raison quelconque (par exemple : une absence de germination, une destruction accidentelle d’une parcelle, des enregistrements incorrects, …), un facteur à l’étude est non disponible.

----------------------------------------

Les valeurs manquantes sont dites monotones lorsque la valeur d’une variable  manquante pour un individu  implique que toutes les variables suivantes  ,   sont manquantes pour cet individu (figure 1.b). Elles sont dites arbitraires ou non monotones ou encore générales, lorsque la matrice ne dessine spécifiquement aucune des formes précédentes (figure 1.c).

a) non-réponse univariée

b) Non-réponse monotone

c) Non-réponse générale
NB : les lignes sont les observations et les colonnes correspondent aux variables
Figure 1 : Exemple de profils de données manquantes
            1.3.2 Mécanismes conduisant aux données manquantes
Les mécanismes conduisant aux données manquantes décrivent la relation entre les valeurs manquantes et celles observées des variables de la table (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002). En considérant la table de donnée Y =   où O = () représente les données observées et M = () la matrice indicatrice des données manquantes, le mécanisme à l’origine des données manquantes est défini par la distribution conditionnelle de M sachant Y.
Lorsque la probabilité qu’une valeur soit manquante ne dépend ni des valeurs observées, ni de celles manquantes, les données sont dites manquantes complètement au hasard (MCAR : Missing Completely At Random). La probabilité d’absence est donc la même pour toutes les observations et elle ne dépend que de paramètres extérieurs indépendants de cette variable (Collins et al., 2001; Graham, 2012; Heitjan, 1997; Little et Rubin, 2002; Rubin, 1976). Avec de telles données (MCAR), les régressions qui n’utilisent que les enregistrements complets, les moyennes des cas disponibles, les tests non paramétriques et les méthodes basées sur les "moments", sont toutes valides (Heitjan, 1997). Toutefois, une perte de précision est à prévoir dans les résultats (Collins et al., 2001).
Selon les mêmes auteurs, lorsque la probabilité qu’une valeur soit manquante dépend uniquement de la composante observée "O" (une ou plusieurs variables observées) mais pas des valeurs manquantes elles-mêmes, les données sont dites manquantes au hasard (MAR : missing at random). Dans ce cas, les méthodes du maximum de vraisemblance sont valides pour estimer les paramètres du modèle. Les procédures d'imputation multiples utilisent implicitement le mécanisme MAR (Collins et al., 2001; Heitjan, 1997).
Lorsque la probabilité qu'une valeur manque dépend de la valeur non observée de la variable elle-même (M), les données ne manquent pas au hasard (MNAR : Missing Not At Random). Ce type de données ne doit pas être ignoré dans l’ajustement de modèles car elles induisent une perte de précision (inhérente à tout cas de données manquantes) mais aussi un biais dans l’estimation des paramètres (Collins et al., 2001; Heitjan, 1997).
        1.4 Traitement des données manquantes
La présence de données manquantes dans une analyse peut conduire à des estimés de paramètres biaisés, gonfler les erreurs de type I et II, baisser les performances des intervalles de confiance (Collins et al., 2001) et entacher la généralisation des résultats (Taylor et al., 2002). Plusieurs méthodes existent pour calculer des estimés de paramètres de modèles approximativement sans biais, en présence de données manquantes. 
            1.4.1 L’analyse des cas complets
Cette méthode consiste à exclure du fichier de données tous les individus ayant au moins une donnée manquante (Glasson-Cicognani et Berchtold, 2010). Elle serait la plus utilisée pour traiter les valeurs manquantes mais n’est efficace que pour les cas de données manquant complètement au hasard (MCAR) lorsque le nombre de d’observations à éliminer n’est pas trop important (Davey et al., 2001).
            1.4.2 La méthode du maximum de vraisemblance avec les données disponibles
La méthode du maximum de vraisemblance choisit des valeurs de paramètres qui attribuent la plus grande (densité de) probabilité aux valeurs des données observées, dans une famille définie de modèles de probabilité paramétriques (Collins et al., 2001). Les estimés initiaux des paramètres du modèle (issus par exemple, de l’analyse des cas complets) sont optimisés sur toutes les données disponibles (cas complets et ceux avec des valeurs manquantes). Ces nouveaux estimés sont ensuite réutilisés pour la détermination des paramètres du modèle dans un processus d'optimisation répété jusqu'à ce que les estimés du paramètre convergent (Davey et al., 2001). 
Cette méthode fournit des estimés ponctuels et des intervalles de confiance valides pour les paramètres de la population. Mais selon Davey et al. (2001), étant donné qu’elle est basée sur un modèle (model-based technique) plutôt que sur les données, les estimés des mêmes paramètres et de leurs intervalles de confiance peuvent varier d'une analyse à l'autre.
            1.4.3 L’imputation
L’imputation permet de créer des bases de données complètes (Donzé, 2001). Elle corrige la non-réponse partielle en substituant une "valeur artificielle" à la valeur manquante. Les auteurs distinguent l’imputation unique et l’imputation multiple.
                1.4.3.1 L’imputation unique
L’imputation unique consiste à remplacer chaque donnée manquante par une seule valeur plausible telle que la moyenne calculée sur les données réellement observées, l’imputation par le ou les plus proche(s) voisin(s). Cette dernière remplace les données manquantes par des valeurs provenant d’individus similaires pour lesquels toute l’information a été observée. L’imputation peut aussi se faire par régression en remplaçant les valeurs manquantes par des valeurs prédites selon un modèle de régression ou des méthodes bayésiennes plus sophistiquées. L’imputation unique est valide en présence de données manquantes de type MAR (Davey et al., 2001; Donzé, 2001; Glasson-Cicognani et Berchtold, 2010).
Selon Heitjan (1997), il n'existe pas de règles strictes pour décider quand il faut entreprendre une imputation multiple. Néanmoins, si la fraction des observations avec des données manquantes est inférieure à, par exemple, 5%, et le mécanisme est ignorable (MCAR ou MAR), les analyses les plus simples sont satisfaisantes.
                1.4.3.2 L’imputation multiple
L’imputation multiple consiste à imputer plusieurs fois les valeurs manquantes et à combiner les résultats pour diminuer l’erreur causée par la complétion (Davey et al., 2001). Les valeurs manquantes sont remplacées par M (M > 1) ensembles de valeurs simulées donnant lieu à M versions plausibles mais différentes des données complètes (Collins et al., 2001; Taylor et al., 2002). En pratique, seulement M allant de 5 à 10 (imputations) est suffisant pour produire des bonnes inférences (Collins et al., 2001; Donzé, 2001). Chacun des M ensembles de données est analysé de la même manière par des méthodes standards d’analyse de données complètes, et les résultats sont combinés en utilisant une arithmétique simple : les moyennes des paramètres estimés sont calculées, les erreurs standards sont combinées pour refleter l'incertitude des données manquantes et l’erreur d'échantillonnage.
L’imputation multiple est une procédure basée sur un modèle (model-based). L’utilisateur doit spécifier un modèle de probabilité conjointe pour les données observées et manquantes (Collins et al., 2001; Taylor et al., 2002).

## Valeurs et échantillons aberrants: définition, origines, méthodes de détection et traitement

### Définitions 

En analyse univariée, une valeur aberrante est une "donnée observée" pour une variable qui semble anormale au regard des valeurs dont on dispose pour les autres observations de l'échantillon (Planchon, 2005). En analyse multivariée, l’échantillon aberrant résulte d’une grosse erreur se trouvant dans un des composants du vecteur de réponse, ou de petites erreurs systématiques dans chacun de ses composants, et qui de ce fait, ne partage pas les relations entre les variables de la population (Planchon, 2005).
La valeur ou l’observation aberrante est statistiquement discordante dans le contexte d’un modèle de probabilité supposé connu (Barnett et Lewis, 1994; Grubbs, 1969; Munoz-Garcia et al., 1990; Pires et Santos-Pereira, 2005). Leur présence dans les données peut conduire à des estimateurs de paramètres biaisés et, suite à la réalisation de tests statistiques, à une interprétation des résultats erronée (Planchon, 2005). 
        2.2 Origines 
Dans une collecte de données, plusieurs sources de variabilité peuvent mener à des données aberrantes : la variabilité inhérente ou erreur systématique, l’erreur de mesure et l’erreur d’exécution (figure 2) (Barnett et Lewis, 1994; Planchon, 2005). 

   Source : (Barnett, Lewis, 1994)
Figure 2 : Schéma général de traitement des valeurs aberrantes 
La variabilité inhérente est celle par laquelle les observations varient naturellement de manière aléatoire à travers la population. L’erreur de mesure renferme les inadéquations au niveau de la méthode de mesure, des instruments de mesure, l’arrondi des valeurs obtenues ou les erreurs d’enregistrement. Cette erreur est donc liée à des circonstances bien déterminées. Les erreurs d’exécution interviennent également dans des circonstances bien déterminées. Ce sont les erreurs de manipulation, les erreurs commises dans l’assemblage des données, ou lors du traitement informatique. 
L’examen des valeurs aberrantes dans une base de données a pour objectif de les identifier pour soit les supprimer, soit les conserver, ou les corriger avant d'ajuster des modèles non robustes (Filzmoser et al., 2008; Planchon, 2005). La valeur extrême peut être liée à un événement atypique, mais néanmoins connu et intéressant à étudier. Dans ce cas elle est importante à conserver. La correction (ou accommodation) évite le rejet des observations aberrantes et consiste à estimer les valeurs des paramètres de la distribution de base de façon relativement libre sans déformation des résultats liés à leur présence (Barnett et Lewis, 1994).
        2.3 Détection et traitement des échantillons aberrants multivariés 
L’approche d’identification des observations aberrantes selon Davies et Gather (1993) est de supposer qu’elles ont une distribution différente de celle du reste des observations. Reimann et al. (2005) les distinguent ainsi des valeurs extrêmes qui, bien qu’éloignées du centre du nuage, appartiennent à la même distribution que les autres observations.
En analyse univariée, les méthodes graphiques telles que le diagramme de dispersion des observations classées en fonction de leur rang, les boxplots, les graphiques des quantiles de valeurs brutes ou des résidus, permettent de signaler la présence de valeurs aberrantes (Planchon, 2005). En analyse multivariée, il existe deux approches fondamentales d’identification des valeurs aberrantes : celles basées sur le calcul de distances et les méthodes par projection (Filzmoser et al., 2008; Hadi et al., 2009). 
            2.3.1 Approches basées sur les distances
                2.3.1.1 La distance de Mahalanobis
Les méthodes basées sur la distance détectent les valeurs aberrantes en calculant la distance, généralement la distance de Mahalanobis entre un point particulier et le centre des données (Filzmoser et al., 2008; Pires et Santos-Pereira, 2005). Pour un échantillon x  multivarié à p-dimensions (variables), la distance de Mahalanobis est définie par (Filzmoser et al., 2008) :
     pour 
où  est la moyenne arithmétique multivariée (le centroïde) et  la matrice de variance-covariances de l’échantillon.
Cette distance indique à quel point chaque observation est éloignée du centre du nuage multivarié créé par les données (Alameddine et al., 2010; Davies et Gather, 1993). D’après Alameddine et al. (2010), lorsque les données sont supposées suivre une distribution normale, les carrés des distances  calculées peuvent être considérés comme suivant une distribution du chi-carré. Par convention, tout point qui a une  dépassant un quantile donné de la distribution du chi-carré (par exemple, , le quantile 97,5% avec p (le nombre de variables) degrés de liberté), est considéré comme atypique et identifié comme une valeur aberrante (Filzmoser et al., 2005). Les observations aberrantes multivariées peuvent ainsi être définies comme des observations ayant une grande distance de Mahalanobis (). 
L’inconvénient avec les méthodes basées sur les distances réside dans la difficulté d’obtenir des estimés robuste de la moyenne  et de la matrice de variance-covariances  puisque la distance de Mahalanobis est elle-même sensible aux données extrêmes. De plus, il serait difficile de fixer la valeur critique idéale de M permettant de séparer les valeurs aberrantes des points réguliers (Filzmoser et al., 2005; Filzmoser et al., 2008). 
Différentes méthodes robustes (qui s’accommodent de la présence de points extrêmes) de détection des valeurs aberrantes sont présentées dans la littérature telles que la méthode du volume minimum de l’ellipsoïde (MVE : Minimum Volume Ellipsoid), du déterminant minimum de la matrice de covariance (MCD : Minimum Covariance Matrix determinant), et les estimateurs de type maximum de vraisemblance (M-estimators) (Alameddine et al., 2010; Filzmoser et al., 2008). Ces méthodes calculent des distances robustes similaires aux distances de Mahalanobis, mais remplacent les matrices des moyennes  et des covariances  respectivement par un seuil critique multivarié robuste (t) et un estimateur d'échelle (S) qui ne sont pas influencés par les valeurs aberrantes (Alameddine et al., 2010).
                2.3.1.2 La méthode du volume minimum de l’ellipsoïde (MVE)
Le volume minimum de l’ellipsoïde est le plus petit ellipsoïde régulier couvrant au moins  éléments de l'ensemble des données  où l'estimateur de localisation est le centre de cet ellipsoïde et l'estimateur de dispersion correspond à sa matrice de covariance.  est fixé à priori supérieur ou égal à , où  est le nombre total de points du nuage de données. Le seuil de détection qui est la fraction des valeurs aberrantes qui, lorsqu'elle est dépassée entraîne des estimés totalement biaisés est de l’ordre de 50% à mesure que n augmente (Alameddine et al., 2010; Croux et al., 2002; Filzmoser et al., 2005; Van Aelst et Rousseeuw, 2009).
L'algorithme MVE est initié en choisissant au hasard un ensemble de  points de données pour estimer le modèle majoritaire, où  est le nombre de variables. Cet ensemble initial est alors augmenté pour contenir les  points de données. L'algorithme passe par plusieurs itérations avant de converger sur l'ensemble des points les plus rapprochés qui auront le plus petit volume d'ellipsoïde (Alameddine et al., 2010).
                2.3.1.3 La méthode du déterminant minimum de la matrice de covariance (MCD)
La méthode du déterminant minimum de la matrice de covariance a pour objectif de trouver  observations de l'ensemble de données X = {,. . . , } ⊂ ,  dont la matrice de covariance a le plus petit déterminant. Comme avec la méthode MVE, l'estimateur de localisation est la moyenne de ces  points et celui de la dispersion est proportionnel à la matrice de covariance (Filzmoser et al., 2005; Hubert et Debruyne, 2010; Rousseeuw et Van Driessen, 1999).
Mais en cas de dissymétrie des données, ces tests (MVE, MCD) ne seraient pas applicables (Planchon, 2005). Les estimateurs de type M et les méthodes par projection contournent cette contrainte.
                2.3.1.4 Les estimateurs de type M (maximum de vraisemblance)
Les estimateurs de type M attribuent des poids différents à chaque observation en tenant compte de la dimension des données (nombre de variables) et de la distance robuste qui sépare l'observation du centre de l'ensemble de données. En particulier, si un point est situé en dehors de la limite du nuage multivariée, il est déprécié jusqu'à ce qu'il atteigne une limite externe où il lui est attribué la pondération zéro. Ainsi, les estimateurs de type M accommodent les observations aberrantes potentielles en réduisant leur impact, ou les éliminent (Alameddine et al., 2010).
            2.3.2 Les méthodes par projection
Ces méthodes de détection des observations aberrantes trouvent des projections appropriées des données dans lesquelles les observations aberrantes sont facilement apparentes. Ces observations sont ensuite pondérés pour produire un estimateur robuste pouvant être utilisé pour identifier les observations aberrantes (Filzmoser et al., 2008). Ces méthodes n'assument pas une distribution particulière des données mais cherchent des projections utiles. Elles ne sont donc pas affectées par la non-normalité et s’appliquent sur divers types de distributions (Filzmoser et al., 2008; Hadi et al., 2009). Le but de cette projection exploratoire est d'utiliser les données pour trouver des projections minimales (à une, deux ou trois dimensions) qui fournissent les vues les plus révélatrices des données complètes (Friedman, 1987). La méthode attribue un indice numérique à chaque projection en fonction de la densité des données projetée pour capturer le degré de structure non linéaire présent dans la distribution projetée (Friedman, 1987; Hadi et al., 2009). Ce qui introduit le concept de l’ordination multivariée.
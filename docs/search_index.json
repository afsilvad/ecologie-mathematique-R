[
["chapitre-outliers.html", "9 Détection de valeurs aberrantes et imputation de données manquantes 9.1 Données manquantes, définition, origine, typologie et traitement 9.2 Valeurs et échantillons aberrants: définition, origines, méthodes de détection et traitement", " 9 Détection de valeurs aberrantes et imputation de données manquantes ️ Objectifs spécifiques: À la fin de ce chapitre, vous saurez comment détecter des valeurs aberrantes en mode univarié et multivarié saurez comment procéder à l’imputation de valeurs manquantes en mode univarié et multivarié Note. Ce chapitre a été initialement rédigé par Zonlehoua Coulibali, qui a gratieusement accepté de le partagé pour constutuer ces notes de cours. Le texte a été adapté au format du manuel par Serge-Étienne Parent. Les données environnementales sont généralement recueillies à différentes échelles et concernent plusieurs sites, plusieurs variables (corrélées ou non), impliquent différents individus de différentes agences et peuvent s’étendre sur plusieurs années (Alameddine et al., 2010; Lokupitiya et al., 2006). De ce fait, la plupart de ces bases de données contiennent des valeurs manquantes et/ou aberrantes liées à différentes sources d’erreurs, pouvant parfois limiter l’utilité des inférences statistiques (Collins et al., 2001; Glasson-Cicognani et Berchtold, 2010). Il convient alors de les traiter correctement avant d’effectuer les analyses statistiques car les ignorer peut entraîner, outre une perte de précision, de forts biais dans les modèles d’analyse (Alameddine et al., 2010; Filzmoser et al., 2008; Glasson-Cicognani et Berchtold, 2010). 9.1 Données manquantes, définition, origine, typologie et traitement 9.1.1 Définition Les tableaux de données sont organisés en lignes et colonnes. Les lignes représentent les observations, les unités, les sujets ou les cas étudiés selon le contexte, et les colonnes représentent les variables mesurées pour chaque observation. Les entrées qui sont les valeurs (ou contenus) des cellules ou encore les valeurs observées, peuvent être des valeurs continues, ou des valeurs catégoriales (Little et Rubin, 2002). Considérant une variable aléatoire \\(X\\) quelconque, une donnée manquante \\(x_m\\), est une donnée pour laquelle la valeur de la variable \\(X\\) est inconnue (ou absente). En d’autres termes, on ne dispose pas de la valeur de \\(X\\) pour le sujet \\(i\\) donné. C’est une donnée non disponible qui serait utile pour l’analyse si elle était observée (Ware et al., 2012). La littérature sur les données manquantes est plus abondante dans les domaines des sciences sociales sur les données d’enquêtes, et des sciences médicales (Davey et al., 2001; Graham, 2012). Pour représenter leur répartition dans la table de données, une matrice indicatrice des valeurs manquantes \\(M = (m_{ij})\\) est généralement utilisée où \\(m_{ij}\\) est une variable binaire qui prend la valeur 1 si la valeur de la variable (\\(X\\)) est observée et 0 si \\(x\\) est absent (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002). 9.1.2 Origines des données manquantes Les données manquantes ont des origines matérielles diverses. Des valeurs peuvent être absentes soit parce qu’elles n’ont pas été observées, ou qu’elles ont été perdues ou étaient incohérentes (Glasson-Cicognani et Berchtold, 2010. La donnée peut avoir été perdue lors de la collecte ou du processus d’enregistrement des données, en raison du dysfonctionnement d’un équipement, en raison d’une contamination, ou que la personne responsable de la collecte de données ait simplement oublié d’obtenir cette mesure particulière (Graham, 2012). Pour une base colligeant des résultats de plusieurs études, certaines variables peuvent ne pas avoir été étudiées pour un essai donné selon les objectifs de l’étude. 9.1.3 Profils des données manquantes Les auteurs traitant des données manquantes distinguent des formes de répartition des données manquantes et des mécanismes conduisant à ces dernières. La répartition des données manquantes décrit les dispositions des valeurs présentes et celles qui sont manquantes dans la matrice indicatrice. Les mécanismes à l’origine des données manquantes décrivent la relation probabiliste entre les valeurs observées et les valeurs manquantes de la table de données. 9.1.3.1 Répartition des données manquantes Les données manquantes se répartissent selon différents cas de figures (Graham, 2012; Little et Rubin, 2002) dont les trois principaux sont les valeurs manquantes univariées, les valeurs manquantes monotones et celles non monotones ou arbitraires. Cette distinction est fonction de la matrice indicatrice des valeurs manquantes. Cette matrice est dite à valeurs manquantes univariées ou de non-réponse univariée, lorsque pour une variable donnée, si une observation est absente, alors toutes les observations suivantes pour cette variable sont absentes (figure 9.1a). En expérimentation agricole, ce cas de figure est qualifié de problème de la parcelle manquante où, pour une raison quelconque (par exemple : une absence de germination, une destruction accidentelle d’une parcelle ou des enregistrements incorrects), un facteur à l’étude est non disponible. Les valeurs manquantes monotones surviennent lorsque la valeur d’une variable \\(Y_j\\) manquante pour un individu \\(i\\) implique que toutes les variables suivantes \\(Y_k\\) (\\(k &gt; j\\)) sont manquantes pour cet individu (figure 9.1b). Les valeurs manquantes arbitraires ou non monotones ou encore générales, surviennent lorsque la matrice ne dessine spécifiquement aucune des formes précédentes (figure 9.1c). Figure 9.1: Exemple de profils de données manquantes Le module VIM permet de visualiser la structure des données manquantes. ## Loading required package: colorspace ## Loading required package: grid ## Loading required package: data.table ## VIM is ready to use. ## Since version 4.0.0 the GUI is in its own package VIMGUI. ## ## Please use the package to use the new (and old) GUI. ## Suggestions and bug-reports can be submitted at: https://github.com/alexkowa/VIM/issues ## ## Attaching package: &#39;VIM&#39; ## The following object is masked from &#39;package:datasets&#39;: ## ## sleep ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.3.0 ## ✔ tibble 2.0.1 ✔ dplyr 0.8.0.1 ## ✔ tidyr 0.8.2 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::between() masks data.table::between() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::first() masks data.table::first() ## ✖ dplyr::lag() masks stats::lag() ## ✖ dplyr::last() masks data.table::last() ## ✖ purrr::transpose() masks data.table::transpose() Pour l’exemple, prenons le tableau iris puis remplaçons au hazard des données par des valeurs manquantes (NA), puis vérifions les proportions de données manquantes et les proportions de combinaisons de données manquantes. set.seed(2868374) data(&quot;iris&quot;) iris_NA &lt;- iris n_NA &lt;- 20 row_NA &lt;- sample(1:nrow(iris), n_NA, replace = TRUE) col_NA &lt;- sample(1:ncol(iris), n_NA, replace = TRUE) for (i in 1:n_NA) iris_NA[row_NA[i], col_NA[i]] &lt;- NA summary(aggr(iris_NA, sortVar = TRUE)) ## ## Variables sorted by number of missings: ## Variable Count ## Petal.Length 0.04666667 ## Petal.Width 0.03333333 ## Sepal.Length 0.02000000 ## Sepal.Width 0.02000000 ## Species 0.01333333 ## ## Missings per variable: ## Variable Count ## Sepal.Length 3 ## Sepal.Width 3 ## Petal.Length 7 ## Petal.Width 5 ## Species 2 ## ## Missings in combinations of variables: ## Combinations Count Percent ## 0:0:0:0:0 131 87.3333333 ## 0:0:0:0:1 2 1.3333333 ## 0:0:0:1:0 4 2.6666667 ## 0:0:1:0:0 6 4.0000000 ## 0:0:1:1:0 1 0.6666667 ## 0:1:0:0:0 3 2.0000000 ## 1:0:0:0:0 3 2.0000000 Avec la fonction matrixplot, il est possible de visualiser les données manquantes en rouge, tandisque les données présentes prennent un niveau de gris selon leur valeur. matrixplot(iris_NA) 9.1.3.2 Mécanismes conduisant aux données manquantes Les mécanismes conduisant aux données manquantes décrivent la relation entre les valeurs manquantes et celles observées des variables de la table (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002). En considérant la table de donnée \\(Y = \\{O,M\\}\\) où \\(O = \\left[ o_{i, j} \\right]\\) représente les données observées et \\(M = \\left[ m_{i, j} \\right]\\) la matrice indicatrice des données manquantes, le mécanisme à l’origine des données manquantes est défini par la distribution conditionnelle de \\(M\\) sachant \\(Y\\). Lorsque la probabilité qu’une valeur soit manquante ne dépend ni des valeurs observées, ni de celles manquantes, les données sont dites manquantes complètement au hasard (* MCAR, missing completely at random*). La probabilité d’absence est donc la même pour toutes les observations et elle ne dépend que de paramètres extérieurs indépendants de cette variable (Collins et al., 2001; Graham, 2012; Heitjan, 1997; Little et Rubin, 2002; Rubin, 1976). Avec de telles données (MCAR), les régressions qui n’utilisent que les enregistrements complets, les moyennes des cas disponibles, les tests non-paramétriques et les méthodes basées sur les “moments”, sont toutes valides (Heitjan, 1997). Toutefois, une perte de précision est à prévoir dans les résultats (Collins et al., 2001). Selon les mêmes auteurs, lorsque la probabilité qu’une valeur soit manquante dépend uniquement de la composante observée “O” (une ou plusieurs variables observées) mais pas des valeurs manquantes elles-mêmes, les données sont dites manquantes au hasard (* MAR: missing at random*). Dans ce cas, les méthodes du maximum de vraisemblance sont valides pour estimer les paramètres du modèle. Les procédures d’imputation multiples utilisent implicitement le mécanisme MAR (Collins et al., 2001; Heitjan, 1997). Lorsque la probabilité qu’une valeur manque dépend de la valeur non observée de la variable elle-même (\\(M\\)), les données ne manquent pas au hasard (* MNAR: missing not at random*). Ce type de données ne doit pas être ignoré dans l’ajustement de modèles car elles induisent une perte de précision (inhérente à tout cas de données manquantes) mais aussi un biais dans l’estimation des paramètres (Collins et al., 2001; Heitjan, 1997). 9.1.4 Traitement des données manquantes La présence de données manquantes dans une analyse peut conduire à des estimés de paramètres biaisés, gonfler les erreurs de type I et II, baisser les performances des intervalles de confiance (Collins et al., 2001) et entacher la généralisation des résultats (Taylor et al., 2002). Plusieurs méthodes existent pour calculer des estimés de paramètres de modèles approximativement sans biais, en présence de données manquantes. 9.1.4.1 L’analyse des cas complets Cette méthode consiste à exclure du fichier de données tous les individus ayant au moins une donnée manquante (Glasson-Cicognani et Berchtold, 2010. Elle serait la plus utilisée pour traiter les valeurs manquantes mais n’est efficace que pour les cas de données manquant complètement au hasard (MCAR) lorsque le nombre de d’observations à éliminer n’est pas trop important (Davey et al., 2001). En R, de manière générique, il est possible d’identifier une donnée manquante dans un tableau, une matrice ou un vecteur avec is.na, qui retourne un objet booléen (TRUE / FALSE). La fonction any pernmet d’identifier si au moins une valeur est vraie ou fausse dans un objet, alors que la fonction all permet d’identifier si toutes les valeurs sont vraies. On pourra vérifier si une ligne contient une valeur manquante avec la fontion apply, dans l’axe des lignes. Il faudra toutefois inverser le résultat booléen avec un ! pour faire en sorte que l’on écarte les valeurs manquantes. row_missing &lt;- iris_NA %&gt;% filter(apply(., 1, function(x) any(is.na(x)))) row_complete &lt;- iris_NA %&gt;% filter(!apply(., 1, function(x) any(is.na(x)))) row_missing ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 NA 3.4 1.4 0.3 setosa ## 2 4.4 NA 1.4 0.2 setosa ## 3 5.4 3.7 NA 0.2 setosa ## 4 5.7 3.8 NA NA setosa ## 5 5.1 NA 1.7 0.5 setosa ## 6 4.7 3.2 1.6 NA setosa ## 7 NA 3.4 1.5 0.4 setosa ## 8 5.0 3.5 NA 0.3 setosa ## 9 4.8 3.0 1.4 NA setosa ## 10 5.2 2.7 3.9 1.4 &lt;NA&gt; ## 11 5.6 3.0 NA 1.5 versicolor ## 12 6.1 2.8 NA 1.2 versicolor ## 13 5.4 3.0 4.5 1.5 &lt;NA&gt; ## 14 6.1 NA 4.6 1.4 versicolor ## 15 5.8 2.6 NA 1.2 versicolor ## 16 NA 2.7 5.1 1.9 virginica ## 17 6.7 2.5 5.8 NA virginica ## 18 6.3 3.4 5.6 NA virginica ## 19 6.4 3.1 NA 1.8 virginica Au lieu de apply, R fournit la fontion raccourci complete.cases. row_missing &lt;- iris_NA %&gt;% filter(complete.cases(.)) Le module tidyr (inclus dans tidyverse) nous facilite la vie avec la fonction tidyr::drop_na, qui retire toutes les lignes contenant au moins une valeur manquante. row_complete &lt;- iris_NA %&gt;% drop_na() 9.1.4.2 La méthode du maximum de vraisemblance avec les données disponibles La méthode du maximum de vraisemblance choisit des valeurs de paramètres qui attribuent la plus grande (densité de) probabilité aux valeurs des données observées, dans une famille définie de modèles de probabilité paramétriques (Collins et al., 2001). Les estimés initiaux des paramètres du modèle (issus par exemple, de l’analyse des cas complets) sont optimisés sur toutes les données disponibles (cas complets et ceux avec des valeurs manquantes). Ces nouveaux estimés sont ensuite réutilisés pour la détermination des paramètres du modèle dans un processus d’optimisation répété jusqu’à ce que les estimés du paramètre convergent (Davey et al., 2001). Cette méthode fournit des estimés ponctuels et des intervalles de confiance valides pour les paramètres de la population. Mais selon Davey et al. (2001), étant donné qu’elle est basée sur un modèle (model-based technique) plutôt que sur les données, les estimés des mêmes paramètres et de leurs intervalles de confiance peuvent varier d’une analyse à l’autre. 9.1.4.3 L’imputation L’imputation permet de créer des bases de données complètes (Donzé, 2001). Elle corrige la non-réponse partielle en substituant une “valeur artificielle” à la valeur manquante. Les auteurs distinguent l’imputation unique et l’imputation multiple. 9.1.4.3.1 L’imputation unique L’imputation unique consiste à remplacer chaque donnée manquante par une seule valeur plausible telle que la moyenne calculée sur les données réellement observées, l’imputation par le ou les plus proche(s) voisin(s) (la technique des plus proches voisins est couverte au chapitre 12). Cette dernière remplace les données manquantes par des valeurs provenant d’individus similaires pour lesquels toute l’information a été observée. L’imputation peut aussi se faire par régression en remplaçant les valeurs manquantes par des valeurs prédites selon un modèle de régression ou des méthodes bayésiennes plus sophistiquées. L’imputation unique est valide en présence de données manquantes de type MAR (Davey et al., 2001; Donzé, 2001; Glasson-Cicognani et Berchtold, 2010. Selon Heitjan (1997), il n’existe pas de règles strictes pour décider quand il faut entreprendre une imputation multiple. Néanmoins, si la fraction des observations avec des données manquantes est inférieure à par exemple 5%, et le mécanisme est ignorable (MCAR ou MAR), les analyses les plus simples sont satisfaisantes. Bien que conçu principalement pour l’imputation multiple (on y arrive bientôt), le module mice permet l’imputation univariée. Nous allons tester l’imputation par la moyenne. Voyons par exemple la moyenne des longueurs des sépales. mean(iris_NA$Sepal.Length[!complete.cases(iris_NA)], na.rm = TRUE) ## [1] 5.54375 Lançons l’imputation par la fonction mice, puis la prédiction du tableau imputé par la fonction complete. library(&quot;mice&quot;) iris_mice &lt;- mice(iris_NA, method = &quot;mean&quot;) ## ## iter imp variable ## 1 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species iris_imp &lt;- complete(iris_mice) Le tableau original peut être comparé au tableau imputé. iris_NA[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 NA 3.4 1.4 0.3 setosa ## 9 4.4 NA 1.4 0.2 setosa ## 11 5.4 3.7 NA 0.2 setosa ## 19 5.7 3.8 NA NA setosa ## 24 5.1 NA 1.7 0.5 setosa ## 30 4.7 3.2 1.6 NA setosa ## 32 NA 3.4 1.5 0.4 setosa ## 41 5.0 3.5 NA 0.3 setosa ## 46 4.8 3.0 1.4 NA setosa ## 60 5.2 2.7 3.9 1.4 &lt;NA&gt; ## 67 5.6 3.0 NA 1.5 versicolor ## 74 6.1 2.8 NA 1.2 versicolor ## 85 5.4 3.0 4.5 1.5 &lt;NA&gt; ## 92 6.1 NA 4.6 1.4 versicolor ## 93 5.8 2.6 NA 1.2 versicolor ## 102 NA 2.7 5.1 1.9 virginica ## 109 6.7 2.5 5.8 NA virginica ## 137 6.3 3.4 5.6 NA virginica ## 138 6.4 3.1 NA 1.8 virginica iris[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 60 5.2 2.7 3.9 1.4 versicolor ## 67 5.6 3.0 4.5 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 92 6.1 3.0 4.6 1.4 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 102 5.8 2.7 5.1 1.9 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 137 6.3 3.4 5.6 2.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica iris_imp[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 5.862759 3.40 1.400000 0.300000 setosa ## 9 4.400000 3.06 1.400000 0.200000 setosa ## 11 5.400000 3.70 3.773759 0.200000 setosa ## 19 5.700000 3.80 3.773759 1.202797 setosa ## 24 5.100000 3.06 1.700000 0.500000 setosa ## 30 4.700000 3.20 1.600000 1.202797 setosa ## 32 5.862759 3.40 1.500000 0.400000 setosa ## 41 5.000000 3.50 3.773759 0.300000 setosa ## 46 4.800000 3.00 1.400000 1.202797 setosa ## 60 5.200000 2.70 3.900000 1.400000 &lt;NA&gt; ## 67 5.600000 3.00 3.773759 1.500000 versicolor ## 74 6.100000 2.80 3.773759 1.200000 versicolor ## 85 5.400000 3.00 4.500000 1.500000 &lt;NA&gt; ## 92 6.100000 3.06 4.600000 1.400000 versicolor ## 93 5.800000 2.60 3.773759 1.200000 versicolor ## 102 5.862759 2.70 5.100000 1.900000 virginica ## 109 6.700000 2.50 5.800000 1.202797 virginica ## 137 6.300000 3.40 5.600000 1.202797 virginica ## 138 6.400000 3.10 3.773759 1.800000 virginica Dans la colonne Sepal.Length, toutes les valeurs manquantes ont été remplacées par ~5.862. Exercice. Pourquoi la prédiction diffère-t-elle de la moyenne? 9.1.4.3.2 L’imputation multiple L’imputation multiple consiste à imputer plusieurs fois les valeurs manquantes et à combiner les résultats pour diminuer l’erreur causée par la complétion (Davey et al., 2001). Les valeurs manquantes sont remplacées par \\(M\\) (\\(M &gt; 1\\)) ensembles de valeurs simulées donnant lieu à \\(M\\) versions plausibles mais différentes des données complètes (Collins et al., 2001; Taylor et al., 2002). En pratique, seulement \\(M\\) allant de 5 à 10 (imputations) est suffisant pour produire des bonnes inférences (Collins et al., 2001; Donzé, 2001). Chacun des \\(M\\) ensembles de données est analysé de la même manière par des méthodes standards d’analyse de données complètes, et les résultats sont combinés en utilisant une arithmétique simple: les moyennes des paramètres estimés sont calculées, les erreurs standards sont combinées pour refleter l’incertitude des données manquantes et l’erreur d’échantillonnage. L’imputation multiple est une procédure basée sur un modèle (model-based). L’utilisateur doit spécifier un modèle de probabilité conjointe pour les données observées et manquantes (Collins et al., 2001; Taylor et al., 2002). Le module mice donne accès à plusieurs types de modèles (argument method). Les modèles cart et rf tombent la la catégorie de l’autoapprentissage (couvert au chapitre 12). Ils ont l’avantage important d’être applicables autant pour tout type de variable. iris_mice &lt;- mice(iris_NA, method = &quot;rf&quot;) ## ## iter imp variable ## 1 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 4 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 2 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 3 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 4 Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5 5 Sepal.Length Sepal.Width Petal.Length Petal.Width Species iris_imp &lt;- complete(iris_mice) De même que précédemment, le tableau original peut être comparé au tableau imputé. iris_NA[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 NA 3.4 1.4 0.3 setosa ## 9 4.4 NA 1.4 0.2 setosa ## 11 5.4 3.7 NA 0.2 setosa ## 19 5.7 3.8 NA NA setosa ## 24 5.1 NA 1.7 0.5 setosa ## 30 4.7 3.2 1.6 NA setosa ## 32 NA 3.4 1.5 0.4 setosa ## 41 5.0 3.5 NA 0.3 setosa ## 46 4.8 3.0 1.4 NA setosa ## 60 5.2 2.7 3.9 1.4 &lt;NA&gt; ## 67 5.6 3.0 NA 1.5 versicolor ## 74 6.1 2.8 NA 1.2 versicolor ## 85 5.4 3.0 4.5 1.5 &lt;NA&gt; ## 92 6.1 NA 4.6 1.4 versicolor ## 93 5.8 2.6 NA 1.2 versicolor ## 102 NA 2.7 5.1 1.9 virginica ## 109 6.7 2.5 5.8 NA virginica ## 137 6.3 3.4 5.6 NA virginica ## 138 6.4 3.1 NA 1.8 virginica iris[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 60 5.2 2.7 3.9 1.4 versicolor ## 67 5.6 3.0 4.5 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 92 6.1 3.0 4.6 1.4 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 102 5.8 2.7 5.1 1.9 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 137 6.3 3.4 5.6 2.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica iris_imp[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.8 3.4 1.4 0.3 setosa ## 9 4.4 3.7 1.4 0.2 setosa ## 11 5.4 3.7 1.4 0.2 setosa ## 19 5.7 3.8 4.2 1.5 setosa ## 24 5.1 3.5 1.7 0.5 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 32 4.9 3.4 1.5 0.4 setosa ## 41 5.0 3.5 1.5 0.3 setosa ## 46 4.8 3.0 1.4 0.2 setosa ## 60 5.2 2.7 3.9 1.4 versicolor ## 67 5.6 3.0 4.2 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 92 6.1 3.1 4.6 1.4 versicolor ## 93 5.8 2.6 4.2 1.2 versicolor ## 102 6.8 2.7 5.1 1.9 virginica ## 109 6.7 2.5 5.8 0.6 virginica ## 137 6.3 3.4 5.6 1.8 virginica ## 138 6.4 3.1 1.5 1.8 virginica Mieux vauit éviter d’imputer des données compositionnelles transformées (alr, clr ou ilr), car l’imputation d’une dimension transformée aura un impact sur tout le vecteur. Dans ce cas, vous pourriez préférablemen utiliser la fonction robCompositions::impCoda. 9.2 Valeurs et échantillons aberrants: définition, origines, méthodes de détection et traitement 9.2.1 Définitions En analyse univariée, une valeur aberrante est une “donnée observée” pour une variable qui semble anormale au regard des valeurs dont on dispose pour les autres observations de l’échantillon (Planchon, 2005). En analyse multivariée, l’échantillon aberrant résulte d’une erreur importante se trouvant dans un des composants du vecteur de réponse, ou de petites erreurs systématiques dans chacun de ses composants, et qui de ce fait, ne partage pas les relations entre les variables de la population (Planchon, 2005). La valeur ou l’observation aberrante est statistiquement discordante dans le contexte d’un modèle de probabilité supposé connu (Barnett et Lewis, 1994; Grubbs, 1969; Munoz-Garcia et al., 1990; Pires et Santos-Pereira, 2005). Leur présence dans les données peut conduire à des estimateurs de paramètres biaisés et, suite à la réalisation de tests statistiques, à une interprétation des résultats erronée (Planchon, 2005). 9.2.2 Origines Dans une collecte de données, plusieurs sources de variabilité peuvent mener à des données aberrantes : la variabilité inhérente ou erreur systématique, l’erreur de mesure et l’erreur d’exécution (figure 9.2) (Barnett et Lewis, 1994; Planchon, 2005). Figure 9.2: Schéma général de traitement des valeurs aberrantes - adapté de Barnett et Lewis, 1994 La variabilité inhérente est celle par laquelle les observations varient naturellement de manière aléatoire à travers la population. L’erreur de mesure renferme les inadéquations au niveau de la méthode de mesure, des instruments de mesure, l’arrondi des valeurs obtenues ou les erreurs d’enregistrement. Cette erreur est donc liée à des circonstances bien déterminées. Les erreurs d’exécution interviennent également dans des circonstances bien déterminées. Ce sont les erreurs de manipulation, les erreurs commises dans l’assemblage des données, ou lors du traitement informatique. L’examen des valeurs aberrantes dans une base de données a pour objectif de les identifier pour soit les supprimer, soit les conserver, ou les corriger avant d’ajuster des modèles non robustes (Filzmoser et al., 2008; Planchon, 2005). La valeur extrême peut être liée à un événement atypique, mais néanmoins connu et intéressant à étudier. Dans ce cas elle est importante à conserver. La correction (ou accommodation) évite le rejet des observations aberrantes et consiste à estimer les valeurs des paramètres de la distribution de base de façon relativement libre sans déformation des résultats liés à leur présence (Barnett et Lewis, 1994). 9.2.3 Détection et traitement des échantillons aberrants multivariés L’approche d’identification des observations aberrantes selon Davies et Gather (1993) est de supposer qu’elles ont une distribution différente de celle du reste des observations. Reimann et al. (2005) les distinguent ainsi des valeurs extrêmes qui, bien qu’éloignées du centre du nuage, appartiennent à la même distribution que les autres observations. En analyse univariée, les méthodes graphiques telles que le diagramme de dispersion des observations classées en fonction de leur rang, les boxplots, les graphiques des quantiles de valeurs brutes ou des résidus, permettent de signaler la présence de valeurs aberrantes (Planchon, 2005). En analyse multivariée, il existe deux approches fondamentales d’identification des valeurs aberrantes: celles basées sur le calcul de distances et les méthodes par projection (Filzmoser et al., 2008; Hadi et al., 2009). 9.2.3.1 Approches basées sur les distances 9.2.3.1.1 La distance de Mahalanobis Les méthodes basées sur la distance détectent les valeurs aberrantes en calculant la distance, généralement la distance de Mahalanobis (vue au chapitre 8) entre un point particulier et le centre des données (Filzmoser et al., 2008; Pires et Santos-Pereira, 2005). Pour un échantillon \\(x\\) multivarié, la distance de Mahalanobis est calculée comme: \\[ \\mathscr{M} = \\sqrt{(\\vec{x}-\\vec{\\mu})^T S^{-1} (\\vec{x}-\\vec{\\mu})}.\\ \\] où \\(\\vec{\\mu}\\) est la moyenne arithmétique multivariée (le centroïde) et \\(S\\) la matrice de variance-covariances de l’échantillon, qui doit être inversée. Cette distance indique à quel point chaque observation est éloignée du centre du nuage multivarié créé par les données (Alameddine et al., 2010; Davies et Gather, 1993). D’après Alameddine et al. (2010), lorsque les données sont supposées suivre une distribution normale, les carrés des distances \\(\\mathscr{M}\\) calculées peuvent être considérés comme suivant une distribution du \\(\\chi^2\\). Par convention, tout point qui a une dépassant un quantile donné de la distribution du \\(\\chi^2\\) (par exemple, \\(\\chi^2_{df = p ; 0.975}\\), le quantile 97,5% avec \\(p\\) (le nombre de variables) degrés de liberté), est considéré comme atypique et identifié comme une valeur aberrante (Filzmoser et al., 2005). Les observations aberrantes multivariées peuvent ainsi être définies comme des observations ayant une grande distance de Mahalanobis (\\(\\mathscr{M}^2\\)). L’inconvénient avec les méthodes basées sur les distances réside dans la difficulté d’obtenir des estimés robuste de la moyenne \\(\\mu\\) et de la matrice de variance-covariances \\(S\\), puisque la distance de Mahalanobis est elle-même sensible aux données extrêmes. De plus, il serait difficile de fixer la valeur critique idéale de \\(\\mathscr{M}\\) permettant de séparer les valeurs aberrantes des points réguliers (Filzmoser et al., 2005; Filzmoser et al., 2008). La fonction sign1 du module mvoutlier détecte les valeurs aberrantes selon un seuil du \\(\\chi^2_{df = 3 ; 0.975}\\) pour les transformations en log-ratio isométriques de Al, Fe et K dans un humus (l’inverse de la matrice de covariance des les log-ratio centrés est singulière). library(&quot;mvoutlier&quot;) library(&quot;compositions&quot;) data(&quot;humus&quot;) sbp &lt;- matrix(c(1, 1,-1,-1, 1,-1, 0, 0, 0, 0, 1,-1), ncol = 4, byrow = TRUE) ilr_elements &lt;- humus %&gt;% select(Al, Fe, K, Na) %&gt;% ilr(., V = gsi.buildilrBase(t(sbp))) %&gt;% as_tibble(.) %&gt;% rename(`[Al,Fe | K,Na]` = V1, `[Al | Fe]` = V2, `[K | Na]` = V3) ## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `enframe(name = NULL)` instead. ## This warning is displayed once per session. is_out &lt;- sign1(ilr_elements, qcrit = 0.975)$wfinal01 plot(ilr_elements, col = is_out + 2) Différentes méthodes robustes (qui s’accommodent de la présence de points extrêmes) de détection des valeurs aberrantes sont présentées dans la littérature telles que la méthode du volume minimum de l’ellipsoïde (MVE, minimum volume ellipsoid), du déterminant minimum de la matrice de covariance (MCD, minimum Covariance matrix determinant), et les estimateurs de type maximum de vraisemblance (M-estimators) (Alameddine et al., 2010; Filzmoser et al., 2008). Ces méthodes calculent des distances robustes similaires aux distances de Mahalanobis, mais remplacent les matrices des moyennes et des covariances respectivement par un seuil critique multivarié robuste (sur \\(\\mu\\)) et un estimateur d’échelle (sur \\(S\\)) qui ne sont pas influencés par les valeurs aberrantes (Alameddine et al., 2010). 9.2.3.1.2 La méthode du volume minimum de l’ellipsoïde (MVE) Le volume minimum de l’ellipsoïde est le plus petit ellipsoïde régulier couvrant au moins \\(h\\) éléments de l’ensemble des données \\(X = \\{x_1, x_2, ..., x_n \\}\\) où l’estimateur de localisation est le centre de cet ellipsoïde et l’estimateur de dispersion correspond à sa matrice de covariance. \\(h\\) est fixé à priori supérieur ou égal à \\(\\frac{n}{2}+1\\), où \\(n\\) est le nombre total de points du nuage de données. Le seuil de détection qui est la fraction des valeurs aberrantes qui, lorsqu’elle est dépassée entraîne des estimés totalement biaisés est de l’ordre de 50% à mesure que \\(n\\) augmente (Alameddine et al., 2010; Croux et al., 2002; Filzmoser et al., 2005; Van Aelst et Rousseeuw, 2009). L’algorithme MVE est initié en choisissant au hasard un ensemble de \\(p+1\\) points de données pour estimer le modèle majoritaire, où \\(p\\) est le nombre de variables. Cet ensemble initial est alors augmenté pour contenir les \\(h\\) points de données. L’algorithme passe par plusieurs itérations avant de converger sur l’ensemble des points les plus rapprochés qui auront le plus petit volume d’ellipsoïde (Alameddine et al., 2010). Le module MASS comprend la fonction cov.mve à cet effet. Cette fonction demande le nombre minimal de points que l’on désire conserver, en absolu. Il s’agit d’un nombre entier, alors si l’on désire en utiliser une fraction (ici, 90%), il faut l’arrondir. Parmi les sorties de la fonction cov.mve, on retrouve les numéros de ligne qui se trouvent à l’intérieur de l’ellipsoide. library(&quot;MASS&quot;) select &lt;- dplyr::select # pour éviter que la fonction select du module MASS remplace celle de dplyr min_in &lt;- round(0.9 * nrow(ilr_elements)) # le minimum de points à garder, 90% du total id_in &lt;- cov.mve(ilr_elements, quantile.used = min_in)$best is_in &lt;- 1:nrow(ilr_elements) %in% id_in plot(ilr_elements, col = is_in + 2) 9.2.3.1.3 La méthode du déterminant minimum de la matrice de covariance (MCD) La méthode du déterminant minimum de la matrice de covariance a pour objectif de trouver \\(h\\) (\\(h &gt; n\\)) observations de l’ensemble de données \\(X = \\{x_1, x_2, ..., x_n \\}\\), dont la matrice de covariance a le plus petit déterminant. Comme avec la méthode MVE, l’estimateur de localisation est la moyenne de ces \\(h\\) points et celui de la dispersion est proportionnel à la matrice de covariance (Filzmoser et al., 2005; Hubert et al., 2018; Rousseeuw et Van Driessen, 1999). id_in &lt;- cov.mcd(ilr_elements, quantile.used = min_in)$best is_in &lt;- 1:nrow(ilr_elements) %in% id_in plot(ilr_elements, col = is_in + 2) Mais en cas de dissymétrie des données, ces tests (MVE, MCD) ne seraient pas applicables (Planchon, 2005). Les estimateurs de type M et les méthodes par projection contournent cette contrainte. 9.2.3.1.4 Les estimateurs de type M (maximum de vraisemblance) Les estimateurs de type M attribuent des poids différents à chaque observation en tenant compte de la dimension des données (nombre de variables) et de la distance robuste qui sépare l’observation du centre de l’ensemble de données. En particulier, si un point est situé en dehors de la limite du nuage multivariée, il est déprécié jusqu’à ce qu’il atteigne une limite externe où il lui est attribué la pondération zéro. Ainsi, les estimateurs de type M accommodent les observations aberrantes potentielles en réduisant leur impact, ou les éliminent (Alameddine et al., 2010). 9.2.3.2 Les méthodes par projection Ces méthodes de détection des observations aberrantes trouvent des projections appropriées des données dans lesquelles les observations aberrantes sont facilement apparentes. Ces observations sont ensuite pondérés pour produire un estimateur robuste pouvant être utilisé pour identifier les observations aberrantes (Filzmoser et al., 2008). Ces méthodes n’assument pas une distribution particulière des données mais cherchent des projections utiles. Elles ne sont donc pas affectées par la non-normalité et s’appliquent sur divers types de distributions (Filzmoser et al., 2008; Hadi et al., 2009). Le but de cette projection exploratoire est d’utiliser les données pour trouver des projections minimales (à une, deux ou trois dimensions) qui fournissent les vues les plus révélatrices des données complètes (Friedman, 1987). La méthode attribue un indice numérique à chaque projection en fonction de la densité des données projetée pour capturer le degré de structure non linéaire présent dans la distribution projetée (Friedman, 1987; Hadi et al., 2009). En R, nous revenons au module mvoutlier, mais cette fois-ci avec la fonction sign2. is_out &lt;- sign2(ilr_elements, qcrit = 0.975)$wfinal01 plot(ilr_elements, col = is_out + 2) "]
]
